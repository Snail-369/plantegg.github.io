---
title: Linux Network Stack
date: 2019-05-24 17:30:03
categories:
    - network
tags:
    - Linux
    - network
    - TCP
---

# Linux Network Stack

一个网络包进到网卡后续如何流转，中间有哪些关键参数，有什么工具能帮忙可以看到各个环节的一些指征，怎么调整他们

## 接收流程

1. 网络包进到网卡，网卡驱动校验MAC，看是否扔掉，取决是否是混杂 promiscuous mode
2. 网卡在启动时会申请一个接收ring buffer，其条目都会指向一个skb的内存。
3. DMA完成数据报文从网卡硬件到内存到拷贝
4. 网卡发送一个中断通知CPU。
5. CPU执行网卡驱动注册的中断处理函数，中断处理函数只做一些必要的工作，如读取硬件状态等，并把当前该网卡挂在NAPI的链表中;
6. Driver “触发” soft IRQ(NET_RX_SOFTIRQ (其实就是设置对应软中断的标志位) 
7. CPU中断处理函数返回后，会检查是否有软中断需要执行。因第三步设置了NET_RX_SOFTIRQ，则执行报文接收软中断。
8. 在NET_RX_SOFTIRQ软中断中，执行NAPI操作，回调第三步挂载的驱动poll函数。
9. 驱动会对interface进行poll操作，检查网卡是否有接收完毕的数据报文。
10. 将网卡中已经接收完毕的数据报文取出，继续在软中断进行后续处理。注：驱动对interface执行poll操作时，会尝试循环检查网卡是否有接收完毕的报文，直到系统设置的net.core.netdev_budget上限(默认300)，或者已经就绪报文。
11. **net_rx_action**
12. 内核分配 sk_buff 内存
13. 内核填充 metadata: 协议等，移除 ethernet 包头信息
14. **将skb 传送给内核协议栈 netif_receive_skb**
15.  `__netif_receive_skb_core`：将数据送到抓包点（tap）或协议层(i.e. tcpdump)
16. 进入到由 netdev_max_backlog 控制的qdisc
17. 开始 **ip_rcv** 处理流程，主要处理ip协议包头相关信息
18. 调用内核 netfilter 框架(iptables PREROUTING)
19. 进入L4 protocol **tcp_v4_rcv**
20. 找到对应的socket
21. 根据 tcp_rmem 进入接收缓冲队列
22. 内核将数据送给接收的应用

>  软中断：可以把软中断系统想象成一系列**内核线程**（每个 CPU 一个），这些线程执行针对不同 事件注册的处理函数（handler）。如果你用过 `top` 命令，可能会注意到 `ksoftirqd/0` 这个内核线程，其表示这个软中断线程跑在 CPU 0 上。

### 典型的接收堆栈

![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2019/png/33359/1557292725626-2e4b452b-8a9e-4d9f-91a6-64357fbd4e0e.png) 

### 从四层协议栈来看收包流程

![image.png](https://ata2-img.cn-hangzhou.oss-pub.aliyun-inc.com/ddd50d2c70215d477d72734b0834410a.png)


### DMA驱动部分流程图

[DMA是一个硬件逻辑](https://ylgrgyq.github.io/2017/07/23/linux-receive-packet-1/)，数据传输到系统物理内存的过程中，全程不需要CPU的干预，除了占用总线之外(期间CPU不能使用总线)，没有任何额外开销。

![image.png](https://ata2-img.cn-hangzhou.oss-pub.aliyun-inc.com/ba2f1764fab3a7b3f485836e8e566ffb.png)

1. 驱动在内存中分配一片缓冲区用来接收数据包，叫做sk_buffer;
1. 将上述缓冲区的地址和大小（即接收描述符），加入到rx ring buffer。描述符中的缓冲区地址是DMA使用的物理地址;
1. 驱动通知网卡有一个新的描述符;
1. 网卡从rx ring buffer中取出描述符，从而获知缓冲区的地址和大小;
1. 网卡收到新的数据包;
1. 网卡将新数据包通过DMA直接写到sk_buffer中。


### 网卡传递数据包到内核的流程图及参数

![image.png](https://ata2-img.cn-hangzhou.oss-pub.aliyun-inc.com/daf7318302c0e7f42fb506d6b47fdbd5.png)

## 发送流程

1. 应用调 sendmsg
2. TCP 分片 skb_buff
3. 根据 tcp_wmem 缓存需要发送的包
4. 构造TCP包头(src/dst port)
5. ipv4 调用 tcp_write_xmit 和 tcp_transmit_skb
6. ip_queue_xmit, 构建 ip 包头(获取目标ip和port)
7. 进入 netfilter 流程 nf_hook()
8. 路由流程 POST_ROUTING
9. ip_output 分片
10. 进入L2 dev_queue_xmit
11. 填入 txqueuelen 队列
12. 进入发送 Ring Buffer tx
13. 驱动触发软中断 soft IRQ (NET_TX_SOFTIRQ)

### 典型的发送堆栈

![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2019/png/33359/1557292508719-5b5a2507-a638-4035-a47a-a8599e69f879.png) 

### 从四层协议栈来看发包流程

![image.png](https://ata2-img.cn-hangzhou.oss-pub.aliyun-inc.com/0126bbb59ac317337ca963ef83817159.png)

`net.core.dev_weight` 用来调整 `__qdisc_run` 的循环处理权重，调大后也就是 `__netif_schedule` 更多的被调用执

用 `sudo ifconfig eth0 txqueuelen **` 来控制qdisc 发送队列长度

## 内核相关参数

### Ring Buffer

Ring Buffer位于NIC和IP层之间，是一个典型的FIFO（先进先出）环形队列。Ring Buffer没有包含数据本身，而是包含了指向sk_buff（socket kernel buffers）的描述符。
可以使用ethtool -g eth0查看当前Ring Buffer的设置：

	$sudo ethtool -g eth0
	Ring parameters for eth0:
	Pre-set maximums:
	RX:		256
	RX Mini:	0
	RX Jumbo:	0
	TX:		256
	Current hardware settings:
	RX:		256
	RX Mini:	0
	RX Jumbo:	0
	TX:		256


上面的例子是一个小规格的ECS，接收队列、传输队列都为256。

	$sudo ethtool -g eth0
	Ring parameters for eth0:
	Pre-set maximums:
	RX:		4096
	RX Mini:	0
	RX Jumbo:	0
	TX:		4096
	Current hardware settings:
	RX:		4096
	RX Mini:	0
	RX Jumbo:	0
	TX:		512

这是一台物理机，接收队列为4096，传输队列为512。接收队列已经调到了最大，传输队列还可以调大。**队列越大丢包的可能越小，但数据延迟会增加**

#### 调整 Ring Buffer 队列数量

```
ethtool -l eth0
Channel parameters for eth0:
Pre-set maximums:
RX:             0
TX:             0
Other:          1
Combined:       8
Current hardware settings:
RX:             0
TX:             0
Other:          1
Combined:       8

sudo ethtool -L eth0 combined 8
sudo ethtool -L eth0 rx 8
```

网卡多队列就是指的有多个RingBuffer，每个RingBufffer可以由一个core来处理

![image.png](https://ata2-img.oss-cn-zhangjiakou.aliyuncs.com/51f13ecb5002f628fbe1900ab8b820aa.png)

#### 网卡各种统计数据查看

	ethtool -S eth0 | grep errors
	
	ethtool -S eth0 | grep rx_ | grep errors //查看网卡是否丢包，一般是ring buffer太小
	
	//监控
	ethtool -S eth0 | grep -e "err" -e "drop" -e "over" -e "miss" -e "timeout" -e "reset" -e "restar" -e "collis" -e "over" | grep -v "\: 0"

#### 网卡进出队列大小调整

	//查看目前的进出队列大小
	ethtool -g eth0
	//修改进出队列
 	ethtool -G eth0 rx 8192 tx 8192

要注意如果设置的值超过了允许的最大值，用默认的最大值，一些ECS之类的虚拟机、容器就不允许修改这个值。

### txqueuelen

ifconfig 看到的 txqueuelen 跟Ring Buffer是两个东西，IP协议下面就是 txqueuelen，txqueuelen下面才到Ring Buffer. 

常用的tc qdisc、netfilter就是在txqueuelen这一环节。 qdisc 的队列长度是我们用 ifconfig 来看到的 txqueuelen

发送队列就是指的这个txqueuelen，和网卡关联着。 而每个Core接收队列由内核参数： net.core.netdev_max_backlog来设置		
		//当前值通过ifconfig可以查看到，修改：
		ifconfig eth0 txqueuelen 2000
		//监控
		ip -s link

如果txqueuelen 太小导致数据包被丢弃的情况，这类问题可以通过下面这个命令来观察：

```
$ ip -s -s link ls dev eth0
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000
    link/ether 00:16:3e:12:9b:c0 brd ff:ff:ff:ff:ff:ff
    RX: bytes  packets  errors  dropped overrun mcast
    13189414480980 22529315912 0       0       0       0
    RX errors: length   crc     frame   fifo    missed
               0        0       0       0       0
    TX: bytes  packets  errors  dropped carrier collsns
    15487121408466 12925733540 0       0       0       0
    TX errors: aborted  fifo   window heartbeat transns
               0        0       0       0       2
```

如果观察到 dropped 这一项不为 0，那就有可能是 txqueuelen 太小导致的。当遇到这种情况时，你就需要增大该值了，比如增加 eth0 这个网络接口的 txqueuelen：

>  $ ifconfig eth0 txqueuelen 2000

### Interrupt Coalescence (IC) - rx-usecs, tx-usecs, rx-frames, tx-frames (hardware IRQ)

这块目前没碰到过瓶颈

		//检查
		ethtool -c eth0
		//修改, 
		ethtool -C eth0 rx-usecs value tx-usecs value
		//监控
		cat /proc/interrupts

### ifconfig 监控指标

- RX overruns: overruns意味着数据包没到Ring Buffer就被网卡物理层给丢弃了，而CPU无法及时的处理中断是造成Ring Buffer满的原因之一，例如中断分配的不均匀。或者Ring Buffer太小导致的（很少见），overruns数量持续增加，建议增大Ring Buffer ，使用ethtool ‐G 进行设置。
- RX dropped: 表示数据包已经进入了Ring Buffer，但是由于内存不够等系统原因，导致在拷贝到内存的过程中被丢弃。如下四种情况导致dropped：Softnet backlog full（pfmemalloc && !skb_pfmemalloc_protocol(skb)--分配内存失败）；Bad / Unintended VLAN tags；Unknown / Unregistered protocols；IPv6 frames
- RX errors：表示总的收包的错误数量，这包括 too-long-frames 错误，Ring Buffer 溢出错误，crc 校验错误，帧同步错误，fifo overruns 以及 missed pkg 等等。

#### overruns

当驱动处理速度跟不上网卡收包速度时，驱动来不及分配缓冲区，NIC接收到的数据包无法及时写到sk_buffer，就会产生堆积，当NIC内部缓冲区写满后，就会丢弃部分数据，引起丢包。这部分丢包为rx_fifo_errors，在 /proc/net/dev中体现为fifo字段增长，在ifconfig中体现为overruns指标增长。


### 监控指标 /proc/net/softnet_stat

#### net.core.netdev_budget

```
sysctl net.core.netdev_budget //默认300， The default value of the budget is 300. This will cause the SoftIRQ process to drain 300 messages from the NIC before getting off the CPU
```

如果 /proc/net/softnet_stat **第三列**一直在增加的话需要，表示SoftIRQ 获取的CPU时间太短，来不及处理足够多的网络包，那么需要增大这个值

增大和查看 net.core.netdev_budget	
		sysctl -a | grep net.core.netdev_budget
		sysctl -w net.core.netdev_budget=400 //临时性增大

#### netdev_max_backlog

The netdev_max_backlog is a queue within the Linux kernel where traffic is stored after reception from the NIC, but before processing by the protocol stacks (IP, TCP, etc). There is one backlog queue per CPU core. 

如果 /proc/net/softnet_stat 第二列一直在增加的话表示netdev backlog queue overflows. 需要增大 netdev_max_backlog

增大和查看 netdev_max_backlog：
	
		sysctl -a |grep netdev_max_backlog
		sysctl -w net.core.netdev_max_backlog=1024 //临时性增大

netdev_max_backlog(接收)和txqueuelen(发送)相对应 

#### softnet_stat

关于`/proc/net/softnet_stat` 的重要细节:

1. 每一行代表一个 `struct softnet_data` 变量。因为每个 CPU 只有一个该变量，所以每行 其实代表一个 CPU
2. 每列用空格隔开，数值用 16 进制表示
3. 第一列 `sd->processed`，是处理的网络帧的数量。如果你使用了 ethernet bonding， 那这个值会大于总的网络帧的数量，因为 ethernet bonding 驱动有时会触发网络数据被 重新处理（re-processed）
4. 第二列，`sd->dropped`，是因为处理不过来而 drop 的网络帧数量。后面会展开这一话题
5. 第三列，`sd->time_squeeze`，前面介绍过了，由于 budget 或 time limit 用完而退出 `net_rx_action` 循环的次数
6. 接下来的 5 列全是 0
7. 第九列，`sd->cpu_collision`，是为了发送包而获取锁的时候有冲突的次数
8. 第十列，`sd->received_rps`，是这个 CPU 被其他 CPU 唤醒去收包的次数
9. 最后一列，`flow_limit_count`，是达到 flow limit 的次数。flow limit 是 RPS 的特性， 后面会稍微介绍一下

### TCP协议栈Buffer

		sysctl -a | grep net.ipv4.tcp_rmem   // receive
		sysctl -a | grep net.ipv4.tcp_wmem   // send
		//监控
		cat /proc/net/sockstat
		
	参考：[TCP性能优化大全](https://www.atatech.org/articles/140017)	

#### 接收Buffer

	$netstat -sn | egrep "prune|collap"; sleep 30; netstat -sn | egrep "prune|collap"
	17671 packets pruned from receive queue because of socket buffer overrun
	18671 packets pruned from receive queue because of socket buffer overrun

如果 “pruning” 一直在增加很有可能是程序中调用了 setsockopt(SO_RCVBUF) 导致内核关闭了动态调整功能，或者压力大，缓存不够了。具体Case：https://blog.cloudflare.com/the-story-of-one-latency-spike/

nstat也可以看到比较多的数据

```
$nstat -z |grep -i drop
TcpExtLockDroppedIcmps          0                  0.0
TcpExtListenDrops               0                  0.0
TcpExtTCPBacklogDrop            0                  0.0
TcpExtPFMemallocDrop            0                  0.0
TcpExtTCPMinTTLDrop             0                  0.0
TcpExtTCPDeferAcceptDrop        0                  0.0
TcpExtTCPReqQFullDrop           0                  0.0
TcpExtTCPOFODrop                0                  0.0
TcpExtTCPZeroWindowDrop         0                  0.0
TcpExtTCPRcvQDrop               0                  0.0
```



## 总体简略收包流程

![](http://img3.tbcdn.cn/L1/461/1/73d01c4c8164ae8642ff09d5d3fe0548d4162874)

带参数版收包流程：

![image.png](https://ata2-img.oss-cn-zhangjiakou.aliyuncs.com/aaf4ff8bbcc26e9e5efe48c984abe508.png)

## 总体简略发送包流程

![](https://intranetproxy.alipay.com/skylark/lark/0/2019/png/33359/1557291324544-ca69d448-08e4-46c4-9c49-8cf516fc3eaa.png)

带参数版发包流程：

![image.png](https://ata2-img.oss-cn-zhangjiakou.aliyuncs.com/955fc732d8620561a9ebce992b0129b1.png)

## 案例

### snat/dnat 宿主机port冲突，丢包

![image.png](https://ata2-img.cn-hangzhou.oss-pub.aliyun-inc.com/d42ccdb0b8f6270d8b559145c0b89c86.png)

1. snat 就是要把 192.168.1.10和192.168.1.11的两个连接替换成宿主机的ip:port
1. 主要是在宿主机找可用port分别给这两个连接用
1. 找可用port分两步
	- 	找到可用port
	- 	将可用port写到数据库，后面做连接追踪用(conntrack)
1. 上述两步不是事务，可能两个连接同时找到一个相同的可用port，但是只有第一个能写入成功，第二个fail，fail后这个包被扔掉
1. 1秒钟后被扔掉的包重传，后续正常

症状：

- 问题发生概率不高，跟压力没有关系，跟容器也没有关系，只要有snat/dnat和并发就会发生，只发生在创建连接的第一个syn包
- 可以通过conntrack工具来检查fail的数量
- 实际影响只是请求偶尔被拉长了1秒或者3秒
- snat规则创建的时候增加参数：NF_NAT_RANGE_PROTO_RANDOM_FULLY 来将冲突降低几个数量级—-可以认为修复了这个问题


		sudo conntrack -L -d ip-addr

来自：https://tech.xing.com/a-reason-for-unexplained-connection-timeouts-on-kubernetes-docker-abd041cf7e02


### 容器(bridge)通过udp访问宿主机服务失败

![image.png](https://ata2-img.cn-hangzhou.oss-pub.aliyun-inc.com/a067b484c593aa3a4b6a525d1f93506e.png)

这个案例主要是讲述回包的逻辑，如果是tcp，那么用dest ip当自己的source ip，如果是UDP，无连接状态信息，那么会根据route来选择一块网卡(上面的IP) 来当source ip

来自：http://cizixs.com/2017/08/21/docker-udp-issue
	 https://github.com/moby/moby/issues/15127


## 参考资料

[The Missing Man Page for ifconfig--关于ifconfig的种种解释](http://blog.hyfather.com/blog/2013/03/04/ifconfig/)

[Linux数据报文的来龙去脉](https://cloud.tencent.com/developer/article/1400834?s=original-sharing)

[Linux TCP队列相关参数的总结--锋寒](https://www.atatech.org/articles/27189)

[linux-network-performance-parameters](https://github.com/leandromoreira/linux-network-performance-parameters)

[Linux之TCPIP内核参数优化](https://www.cnblogs.com/fczjuever/archive/2013/04/17/3026694.html)

https://access.redhat.com/sites/default/files/attachments/20150325_network_performance_tuning.pdf

[Linux 网络协议栈收消息过程-Ring Buffer](https://ylgrgyq.github.io/2017/07/23/linux-receive-packet-1/ ) : 支持 RSS 的网卡内部会有多个 Ring Buffer，NIC 收到 Frame 的时候能通过 Hash Function 来决定 Frame 该放在哪个 Ring Buffer 上，触发的 IRQ 也可以通过操作系统或者手动配置 IRQ affinity 将 IRQ 分配到多个 CPU 上。这样 IRQ 能被不同的 CPU 处理，从而做到 Ring Buffer 上的数据也能被不同的 CPU 处理，从而提高数据的并行处理能力。

[Linux 网络栈监控和调优：发送数据](http://arthurchiao.art/blog/tuning-stack-tx-zh/)

[Linux 网络栈监控和调优：接收数据（2016）](http://arthurchiao.art/blog/tuning-stack-rx-zh/)